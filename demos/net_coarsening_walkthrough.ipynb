{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28397c76",
   "metadata": {},
   "source": [
    "# Network-Coarsened Fiduccia-Mattheyses (FM) Partitioning Walkthrough\n",
    "\n",
    "This notebook provides a comprehensive walkthrough of the **Network-Coarsened FM** algorithm, which is an advanced multilevel partitioning approach that combines:\n",
    "\n",
    "1. **Network Coarsening**: Recursively coarsening the quantum network topology\n",
    "2. **Network Cutting**: Dividing the coarsened network into sub-networks at each level\n",
    "3. **Subgraph Partitioning**: Creating subgraphs with dummy nodes for nieghbouring network regions\n",
    "4. **Multilevel FM**: Applying the Fiduccia-Mattheyses algorithm with temporal coarsening for each subgraph\n",
    "5. **Solution Stitching**: Combining the partitioned subgraphs back into a complete solution\n",
    "\n",
    "The algorithm is effective for large-scale quantum networks where calculating long-range entanglement costs is time consuming.\n",
    "\n",
    "This notebook breaks down the process in detail with visualisations of the coarsened networks and graphs at each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TikZ extension for drawing\n",
    "%load_ext jupyter_tikz\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from qiskit.circuit.library import QuantumVolume\n",
    "from disqco import QuantumNetwork\n",
    "from disqco.graphs.quantum_network import linear_coupling\n",
    "from disqco import QuantumCircuitHyperGraph\n",
    "from disqco.graphs.QC_hypergraph import SubGraphManager\n",
    "from disqco.graphs.coarsening.network_coarsener import NetworkCoarsener\n",
    "from disqco.graphs.coarsening.coarsener import HypergraphCoarsener\n",
    "from disqco.drawing.tikz_drawing import draw_subgraph_tikz\n",
    "from disqco.drawing.mpl_drawing import draw_subgraph_mpl\n",
    "from disqco.parti.FM.net_coarsened_partitioning import check_assignment_validity, stitch_solution_sparse\n",
    "from disqco import set_initial_partition_assignment\n",
    "from disqco.parti.FM.partition_and_build_subgraph import set_initial_partitions_sparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a04a96",
   "metadata": {},
   "source": [
    "## Step 1: Problem Instance Creation\n",
    "\n",
    "First, we create our quantum circuit and network topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem parameters\n",
    "num_qubits = 16\n",
    "num_qpus = 8  # 4-node linear network\n",
    "qpu_capacity = int(np.ceil(num_qubits / num_qpus)) + 1 \n",
    "coarsening_factor = 2  # l=2\n",
    "\n",
    "# Create the quantum circuit (16-qubit Quantum Volume)\n",
    "from qiskit import transpile\n",
    "from disqco.circuits.cp_fraction import cp_fraction\n",
    "\n",
    "# circuit = QuantumVolume(num_qubits, depth=10, seed=42)\n",
    "circuit = cp_fraction(num_qubits, depth=num_qubits, fraction=0.3, seed=764)\n",
    "# Transpile to the right gate set\n",
    "circuit = transpile(circuit, basis_gates=['u', 'cp'])\n",
    "\n",
    "print(f\"‚úÖ Created {num_qubits}-qubit circuit\")\n",
    "print(f\"   Circuit depth: {circuit.depth()}\")\n",
    "gate_counts = circuit.count_ops()\n",
    "print(f\"   Gate counts: {gate_counts}\")\n",
    "\n",
    "# Create the quantum network (4-node linear topology)\n",
    "qpu_sizes = [qpu_capacity] * num_qpus  # [4, 4, 4, 4]\n",
    "connectivity = linear_coupling(num_qpus)  # [(0,1), (1,2), (2,3)]\n",
    "# connectivity = grid_coupling(num_qpus)  \n",
    "\n",
    "\n",
    "initial_network = QuantumNetwork(qpu_sizes, connectivity)\n",
    "\n",
    "network = deepcopy(initial_network)  # Use a copy to avoid modifying the original\n",
    "\n",
    "print(f\"‚úÖ Created {num_qpus}-node linear quantum network\")\n",
    "print(f\"   QPU sizes: {qpu_sizes}\")\n",
    "print(f\"   Connectivity: {connectivity}\")\n",
    "print(f\"   Total capacity: {sum(qpu_sizes)} qubits\")\n",
    "\n",
    "# Create the hypergraph representation\n",
    "hypergraph = QuantumCircuitHyperGraph(circuit)\n",
    "print(f\"‚úÖ Created hypergraph representation\")\n",
    "print(f\"   Number of nodes: {len(hypergraph.nodes)}\")\n",
    "print(f\"   Number of hyperedges: {len(hypergraph.hyperedges)}\")\n",
    "print(f\"   Circuit depth in hypergraph: {hypergraph.depth}\")\n",
    "\n",
    "# Visualize the network topology\n",
    "# Scale figure and node sizes based on network size\n",
    "fig_width = max(8, min(20, num_qpus * 1.5))\n",
    "plt.figure(figsize=(fig_width, 4))\n",
    "\n",
    "plt.title(f\"{num_qpus}-Node Quantum Network\\n(Each node represents a QPU with capacity {qpu_capacity})\", fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "network.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894d661",
   "metadata": {},
   "source": [
    "### Initial Hypergraph Visualization\n",
    "\n",
    "Let's visualize the initial hypergraph representation of our quantum circuit. This shows the temporal structure where each node represents a qubit at a specific time step, and hyperedges represent quantum gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(hypergraph.nodes) < 1500:\n",
    "    fig = hypergraph.draw(network,show_labels=False, display_width=10)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f83160",
   "metadata": {},
   "source": [
    "## Step 2: Network Coarsening\n",
    "\n",
    "The first stage of the algorithm is to coarsen the quantum network. This creates a hierarchy of networks, where each level has fewer nodes but represents the same connectivity structure at a coarser granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d4f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network coarsener\n",
    "net_coarsener = NetworkCoarsener(network)\n",
    "print(f\"üîß Initialized NetworkCoarsener\")\n",
    "print(f\"   Initial network: {net_coarsener.initial_network.num_qpus} QPUs\")\n",
    "\n",
    "# Perform recursive network coarsening\n",
    "print(f\"\\\\nüîÑ Starting recursive network coarsening with l={coarsening_factor}\")\n",
    "start_time = time.time()\n",
    "net_coarsener.coarsen_network_recursive(l=coarsening_factor)\n",
    "coarsening_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Network coarsening complete in {coarsening_time:.4f} seconds\")\n",
    "print(f\"   Number of coarsening levels: {len(net_coarsener.network_coarse_list)}\")\n",
    "\n",
    "# Examine the coarsening hierarchy\n",
    "print(\"\\\\nüìä Network Coarsening Hierarchy:\")\n",
    "for i, network_level in enumerate(net_coarsener.network_coarse_list):\n",
    "    num_nodes = len(network_level.qpu_graph.nodes)\n",
    "    qpu_sizes_level = [network_level.qpu_graph.nodes[node]['size'] for node in network_level.qpu_graph.nodes]\n",
    "    print(f\"   Level {i}: {num_nodes} nodes, sizes {qpu_sizes_level}\")\n",
    "\n",
    "# Set up the final coarsened network\n",
    "final_network = net_coarsener.network_coarse_list[-1]\n",
    "final_network.active_nodes = set(final_network.qpu_graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aea4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the network coarsening hierarchy\n",
    "# Scale figure size based on number of levels and max nodes (vertical layout)\n",
    "max_nodes_in_level = max(len(level.qpu_graph.nodes) for level in net_coarsener.network_coarse_list)\n",
    "fig_width = max(8, max_nodes_in_level * 1.5)  # Wider figure for larger nodes\n",
    "fig_height = max(6, len(net_coarsener.network_coarse_list) * 4)  # Height scales with levels\n",
    "fig, axes = plt.subplots(len(net_coarsener.network_coarse_list), 1, \n",
    "                        figsize=(fig_width, fig_height))\n",
    "\n",
    "if len(net_coarsener.network_coarse_list) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, network_level in enumerate(net_coarsener.network_coarse_list):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Create layout for this network level with adaptive spacing\n",
    "    G = network_level.qpu_graph\n",
    "    num_nodes = len(G.nodes)\n",
    "    \n",
    "    if num_nodes == 1:\n",
    "        pos = {list(G.nodes)[0]: (0, 0)}\n",
    "        spacing = 1\n",
    "    else:\n",
    "        spacing = max(1.0, 6.0 / num_nodes)  # Increased spacing for larger nodes\n",
    "        pos = {node: (idx * spacing, 0) for idx, node in enumerate(G.nodes)}\n",
    "    \n",
    "    # Scale node sizes and font based on number of nodes (increased sizes)\n",
    "    base_size = max(800, 2000 / num_nodes)  # Significantly larger base size\n",
    "    node_sizes = [base_size * G.nodes[node]['size'] / max(G.nodes[n]['size'] for n in G.nodes) for node in G.nodes]\n",
    "    font_size = max(12, min(20, 100 / num_nodes))  # Larger font sizes\n",
    "    \n",
    "    # Create compact labels (without newlines)\n",
    "    if num_nodes <= 8:\n",
    "        node_labels = {node: f\"Q{node}\" for node in G.nodes}\n",
    "    else:\n",
    "        node_labels = {node: f\"Q{node}\" for node in G.nodes}\n",
    "    \n",
    "    # Draw nodes and edges without labels\n",
    "    nx.draw(G, pos=pos, ax=ax, with_labels=False,\n",
    "            node_size=node_sizes, node_color='lightcoral')\n",
    "    \n",
    "    # Create position for labels above nodes\n",
    "    label_pos = {node: (x, y + 0.3) for node, (x, y) in pos.items()}\n",
    "    \n",
    "    # Draw labels above nodes\n",
    "    nx.draw_networkx_labels(G, label_pos, labels=node_labels, ax=ax,\n",
    "                           font_size=int(font_size), font_weight='bold')\n",
    "    \n",
    "    ax.set_title(f\"Level {i}: {len(G.nodes)} nodes\", fontsize=16, fontweight='bold')  # Larger title font\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Adjust axis limits based on spacing\n",
    "    if num_nodes > 1:\n",
    "        ax.set_xlim(-spacing * 0.7, (num_nodes - 1) * spacing + spacing * 0.7)\n",
    "    \n",
    "    # Add more vertical padding\n",
    "    ax.set_ylim(-1, 1)\n",
    "\n",
    "plt.suptitle(\"Network Coarsening Hierarchy\", fontsize=20, fontweight='bold')  # Larger main title\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üé® Network coarsening visualization complete!\")\n",
    "print(\"   Each level shows the network after coarsening operations\")\n",
    "print(\"   Node sizes represent QPU capacities (number of qubits each can handle)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5410e3d",
   "metadata": {},
   "source": [
    "## Step 3: Network Cutting and Sub-Network Generation\n",
    "\n",
    "After coarsening the network, we systematically \"cut\" or divide it into sub-networks at each level. This creates a tree-like structure where each node in a coarser network corresponds to multiple sub-networks in the finer level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network level list with the most coarsened network\n",
    "network_level_list = []\n",
    "network_level_list.append({None: final_network})  # Dict: {source_node: network}\n",
    "networks = network_level_list[0]\n",
    "\n",
    "print(f\"üîß Starting network cutting process\")\n",
    "print(f\"   Initial level has {len(networks)} sub-networks\")\n",
    "\n",
    "# Perform network cutting for each coarsening level\n",
    "start_time = time.time()\n",
    "for i in range(len(net_coarsener.network_coarse_list) - 1):\n",
    "    print(f\"\\nüìÇ Cutting networks at level {i}\")\n",
    "    prev_networks = network_level_list[i]\n",
    "    print(f\"   Input: {len(prev_networks)} networks\")\n",
    "    \n",
    "    new_networks = net_coarsener.cut_network(prev_networks, level=i)\n",
    "    network_level_list.append(new_networks)\n",
    "    \n",
    "    print(f\"   Output: {len(new_networks)} networks\")\n",
    "    \n",
    "    # Show details of the new networks\n",
    "    for source_node, network in new_networks.items():\n",
    "        active_nodes = network.active_nodes\n",
    "        node_sizes = [network.qpu_graph.nodes[node]['size'] for node in active_nodes]\n",
    "        print(f\"     Sub-network {source_node}: {len(active_nodes)} active nodes, sizes {node_sizes}\")\n",
    "\n",
    "cutting_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Network cutting complete in {cutting_time:.4f} seconds\")\n",
    "print(f\"   Total levels created: {len(network_level_list)}\")\n",
    "\n",
    "# Summary of the network hierarchy\n",
    "print(\"\\nüìä Complete Network Hierarchy:\")\n",
    "for level, networks in enumerate(network_level_list):\n",
    "    print(f\"   Level {level}: {len(networks)} sub-networks\")\n",
    "    for source_node, net in networks.items():\n",
    "        active_nodes = net.active_nodes\n",
    "        sizes = [net.qpu_graph.nodes[node]['size'] for node in active_nodes]\n",
    "        print(f\"     Sub-net {source_node}: {len(active_nodes)} nodes, sizes {sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16935b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the network cutting hierarchy\n",
    "print(\"Visualizing network cutting hierarchy...\")\n",
    "\n",
    "max_networks = max(len(networks) for networks in network_level_list)\n",
    "fig_width = max(8, max_networks * 4)  # Wider figure for larger nodes\n",
    "fig_height = max(6, len(network_level_list) * 4)  # Height scales with levels\n",
    "fig, axes = plt.subplots(len(network_level_list), max_networks, \n",
    "                        figsize=(fig_width, fig_height))\n",
    "\n",
    "# Handle case where there's only one level or one network\n",
    "if len(network_level_list) == 1:\n",
    "    axes = [axes]\n",
    "if max_networks == 1:\n",
    "    axes = [[ax] for ax in axes]\n",
    "\n",
    "for level_idx, networks in enumerate(network_level_list):\n",
    "    for net_idx, (source_node, network) in enumerate(networks.items()):\n",
    "        if net_idx < max_networks:  # Ensure we don't exceed subplot grid\n",
    "            ax = axes[level_idx][net_idx]\n",
    "            \n",
    "            G = network.qpu_graph\n",
    "            active_nodes = network.active_nodes\n",
    "            num_nodes = len(G.nodes)\n",
    "            \n",
    "            if num_nodes == 0:\n",
    "                ax.set_title(f\"L{level_idx}-Net{source_node}: Empty\")\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "            \n",
    "            # Sort nodes by index in ascending order for consistent positioning\n",
    "            sorted_nodes = sorted(G.nodes, key=lambda x: (isinstance(x, tuple) and x[0] == 'dummy', x))\n",
    "            \n",
    "            # Create layout with adaptive spacing\n",
    "            if num_nodes == 1:\n",
    "                pos = {sorted_nodes[0]: (0, 0)}\n",
    "                spacing = 1\n",
    "            else:\n",
    "                spacing = max(1.0, 6.0 / num_nodes)  # Increased spacing for larger nodes\n",
    "                pos = {node: (idx * spacing, 0) for idx, node in enumerate(sorted_nodes)}\n",
    "            \n",
    "            # Color nodes: lightcoral for active, lightgrey for inactive/dummy\n",
    "            node_colors = ['lightcoral' if node in active_nodes else 'lightgrey' for node in G.nodes]\n",
    "            \n",
    "            # Scale node sizes (significantly larger like previous visualization)\n",
    "            base_size = max(800, 2000 / num_nodes)\n",
    "            node_sizes = [base_size * G.nodes[node]['size'] / max(G.nodes[n]['size'] for n in G.nodes) for node in G.nodes]\n",
    "            font_size = max(12, min(20, 100 / num_nodes))  # Larger font sizes\n",
    "            \n",
    "            # # Create labels without newlines\n",
    "            # if num_nodes <= 8:\n",
    "            #     node_labels = {node: f\"QPU {node} ({G.nodes[node]['size']})\" for node in sorted_nodes}\n",
    "            # else:\n",
    "            #     node_labels = {node: f\"{node} ({G.nodes[node]['size']})\" for node in sorted_nodes}\n",
    "            \n",
    "            # Draw nodes and edges without labels\n",
    "            nx.draw(G, pos=pos, ax=ax, with_labels=False,\n",
    "                    node_size=node_sizes, node_color=node_colors)\n",
    "            \n",
    "            # Create position for labels above nodes\n",
    "            label_pos = {node: (x, y + 0.3) for node, (x, y) in pos.items()}\n",
    "            \n",
    "            # Draw labels above nodes\n",
    "            nx.draw_networkx_labels(G, label_pos, ax=ax,\n",
    "                                   font_size=int(font_size), font_weight='bold')\n",
    "            \n",
    "            ax.set_title(f\"L{level_idx}:\", \n",
    "                        fontsize=16, fontweight='bold')  # Larger title font\n",
    "            ax.set_aspect('equal')\n",
    "            \n",
    "            # Adjust axis limits based on spacing\n",
    "            if num_nodes > 1:\n",
    "                ax.set_xlim(-spacing * 0.7, (num_nodes - 1) * spacing + spacing * 0.7)\n",
    "            \n",
    "            # Add more vertical padding\n",
    "            ax.set_ylim(-1, 1)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for net_idx in range(len(networks), max_networks):\n",
    "        if net_idx < max_networks:\n",
    "            axes[level_idx][net_idx].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"Network Cutting Hierarchy\", fontsize=20, fontweight='bold')  # Larger main title\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Network cutting visualization complete!\")\n",
    "print(\"   Each row shows a different coarsening level\")\n",
    "print(\"   Each column shows a different sub-network at that level\")\n",
    "print(\"   Red nodes are active in the sub-network, grey nodes are dummy nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808839b",
   "metadata": {},
   "source": [
    "## Initial Partitioning on Coarsest Network\n",
    "\n",
    "Before creating subgraphs, we need to perform an initial partitioning of the circuit on the coarsest network level. This provides the baseline assignment that will be used to determine which nodes become \"dummy nodes\" in each subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51768497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform initial partitioning on the coarsest network\n",
    "print(\"üéØ Performing initial partitioning on coarsest network...\")\n",
    "\n",
    "# Use the coarsest network (first level in our hierarchy)\n",
    "coarsest_networks = network_level_list[0]\n",
    "coarsest_network = list(coarsest_networks.values())[0]\n",
    "coarsest_active_nodes = coarsest_network.active_nodes\n",
    "\n",
    "print(f\"   Coarsest network: {len(coarsest_active_nodes)} active nodes\")\n",
    "print(f\"   Active nodes: {list(coarsest_active_nodes)}\")\n",
    "\n",
    "# Set up initial assignment using simple strategy\n",
    "num_coarsest_qpus = len(coarsest_active_nodes)\n",
    "\n",
    "\n",
    "# Run FM optimization on the coarsest level to get a good starting point\n",
    "print(\"\\\\nüîß Running FM optimization on coarsest network...\")\n",
    "\n",
    "# Create node mapping for coarsest network\n",
    "coarsest_node_map = {list(coarsest_active_nodes)[i] : i for i in range(len(coarsest_active_nodes))}\n",
    "# Create sparse assignment for coarsest network\n",
    "coarsest_qpu_sizes = {qpu: coarsest_network.qpu_graph.nodes[qpu]['size'] for qpu in coarsest_active_nodes}\n",
    "\n",
    "initial_assignment_coarse = set_initial_partition_assignment(\n",
    "    graph=hypergraph,\n",
    "    network=coarsest_network,\n",
    "    node_map=coarsest_node_map,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from disqco.parti.FM.fiduccia import *\n",
    "\n",
    "FM_partitioner = FiducciaMattheyses(circuit=circuit,\n",
    "                                    network=coarsest_network,\n",
    "                                    initial_assignment=initial_assignment_coarse,\n",
    "                                    sparse=True )\n",
    "\n",
    "coarsener = HypergraphCoarsener()\n",
    "coarsening_method = coarsener.coarsen_recursive_subgraph_batch\n",
    "results = FM_partitioner.multilevel_partition(coarsener=coarsening_method, sparse=True)\n",
    "# results = FM_partitioner.partition(sparse=True)\n",
    "\n",
    "optimized_assignment_coarse = results['best_assignment']\n",
    "best_cost = results['best_cost']\n",
    "\n",
    "optimization_time = time.time() - start_time\n",
    "\n",
    "print(f'Best assignment on coarsest network: {optimized_assignment_coarse}')\n",
    "print(f'Best cost on coarsest network: {best_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = draw_subgraph_mpl(hypergraph, \n",
    "                        optimized_assignment_coarse, \n",
    "                        coarsest_qpu_sizes, \n",
    "                        node_map=coarsest_node_map,\n",
    "                        network=coarsest_network,\n",
    "                        fill_background=True, \n",
    "                        show_labels=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc5c78",
   "metadata": {},
   "source": [
    "## Subgraph Creation with Dummy Nodes\n",
    "\n",
    "Now we create subgraphs from the original hypergraph for each sub-network. The key innovation is that nodes belonging to other partitions are replaced with \"dummy nodes\" that represent the external partitions. This allows each subgraph to be optimized independently while maintaining awareness of external dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize subgraph management\n",
    "sub_graph_manager = SubGraphManager(hypergraph)\n",
    "print(f\"üîß Initialized SubGraphManager\")\n",
    "\n",
    "\n",
    "print(networks)\n",
    "\n",
    "# Use the SubGraphManager to create actual subgraphs with dummy nodes\n",
    "subgraphs = sub_graph_manager.build_partition_subgraphs(\n",
    "    graph=hypergraph,\n",
    "    assignment=optimized_assignment_coarse,\n",
    "    current_network=coarsest_network,\n",
    "    new_networks=network_level_list[1],\n",
    "    old_dummy_nodes=set()\n",
    ")\n",
    "\n",
    "print(f\"   ‚úÖ Successfully created {len(subgraphs)} subgraphs with dummy nodes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coarsener = HypergraphCoarsener()\n",
    "\n",
    "# Iterate through dictionary of subgraphs\n",
    "sparse_assignments = []\n",
    "for source_node, subgraph in subgraphs.items():\n",
    "    \n",
    "    sub_network = network_level_list[1][source_node]\n",
    "    active_nodes = sub_network.active_nodes\n",
    "    qpu_sizes = {node: sub_network.qpu_graph.nodes[node]['size'] for node in active_nodes}\n",
    "    node_map = {node: idx for idx, node in enumerate(active_nodes)}\n",
    "\n",
    "\n",
    "    sparse_assignment = set_initial_partitions_sparse(\n",
    "        assignment=optimized_assignment_coarse,\n",
    "        active_nodes=active_nodes,\n",
    "        qpu_sizes=qpu_sizes,\n",
    "        subgraph=subgraph\n",
    "    )\n",
    "\n",
    "\n",
    "    partitioner = FiducciaMattheyses(\n",
    "    circuit=circuit,\n",
    "    initial_assignment=sparse_assignment,\n",
    "    hypergraph=subgraph,\n",
    "    qpu_info=qpu_sizes,\n",
    "    num_partitions=len(active_nodes),\n",
    "    active_nodes=active_nodes,\n",
    "    limit=num_qubits,\n",
    "    max_gain=4*hypergraph.depth,\n",
    "    passes=10,\n",
    "    stochastic=True,\n",
    "    network=sub_network,\n",
    "    node_map=node_map,\n",
    "    sparse=True\n",
    "    )\n",
    "    results = partitioner.partition(hypergraph_coarsener=HypergraphCoarsener().coarsen_recursive_subgraph_batch, \n",
    "                                    sparse=True, level_limit=100, \n",
    "                                    passes_per_level=10)\n",
    "    \n",
    "    sparse_assignment = results['best_assignment']\n",
    "    final_cost = results['best_cost']\n",
    "\n",
    "    fig = draw_subgraph_mpl(subgraph,\n",
    "    sparse_assignment,\n",
    "    qpu_sizes,\n",
    "    network=sub_network,\n",
    "    node_map=node_map,\n",
    "    show_labels=False)\n",
    "    # plt.close()  # Close the figure to avoid overlap with next drawing\n",
    "    \n",
    "    # Check validity of the final sparse assignment\n",
    "    if not check_assignment_validity(sparse_assignment, qpu_sizes, subgraph):\n",
    "        print(\"‚ùå Final sparse assignment is invalid!\")\n",
    "        raise ValueError(\"Final sparse assignment does not respect QPU capacities or active nodes.\")\n",
    "\n",
    "    sparse_assignments.append(sparse_assignment)\n",
    "\n",
    "\n",
    "    \n",
    "print(f\"   ‚úÖ Subgraph {i} TikZ visualization complete!\")\n",
    "\n",
    "print(\"\\\\n‚úÖ Subgraph visualization complete!\")\n",
    "print(\"   Each visualization shows the circuit from one sub-network's perspective\")\n",
    "print(\"   Real nodes belong to the sub-network, dummy nodes represent external qubits\")\n",
    "print(\"   This enables independent optimization while preserving global dependencies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parent_assignment = stitch_solution_sparse(subgraphs, sparse_assignments, num_qubits, depth=hypergraph.depth)\n",
    "\n",
    "final_cost = calculate_full_cost_hetero(hypergraph, parent_assignment, len(initial_network.qpu_sizes), {}, initial_network)\n",
    "\n",
    "print(f\"Final cost of the stitched solution: {final_cost}\")\n",
    "\n",
    "network_level_1 = net_coarsener.network_coarse_list[-2]\n",
    "\n",
    "print(\"Network level 1 QPU sizes:\", network_level_1.qpu_sizes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d60d9",
   "metadata": {},
   "source": [
    "## Step 5.6: Create Second Level Subgraphs\n",
    "\n",
    "Now we create subgraphs for the second level of network coarsening. Each optimized subgraph from the first level is further divided based on the second level of network cutting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ab21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create second level subgraphs\n",
    "print(\"Creating second level subgraphs...\")\n",
    "if len(network_level_list) > 2:\n",
    "    all_new_subgraphs = {}\n",
    "    print(subgraphs)\n",
    "    counter = 0\n",
    "    for i, (source_node, subgraph) in enumerate(subgraphs.items()):\n",
    "        print(f\"\\nüìÇ Processing subgraph {i} (source: {source_node}) for second level...\")\n",
    "        print(f'Counter: {counter}')\n",
    "        counter += 1\n",
    "        \n",
    "        # Get the optimized assignment for this subgraph\n",
    "        optimized_assignment = sparse_assignments[i]\n",
    "        # Find existing dummy nodes\n",
    "        dummy_nodes = set()\n",
    "        for node in subgraph.nodes:\n",
    "            if isinstance(node, tuple) and len(node) > 0 and node[0] == 'dummy':\n",
    "                dummy_nodes.add(node)\n",
    "        \n",
    "        current_network = network_level_list[1][source_node]\n",
    "        \n",
    "        # Create new subgraphs for second level\n",
    "        new_subgraphs = sub_graph_manager.build_partition_subgraphs(\n",
    "            graph=subgraph,\n",
    "            assignment=optimized_assignment,\n",
    "            current_network=current_network,\n",
    "            new_networks=network_level_list[2],\n",
    "            old_dummy_nodes=dummy_nodes\n",
    "        )\n",
    "\n",
    "        all_new_subgraphs.update(new_subgraphs)\n",
    "\n",
    "    print(f\"‚úÖ Created {len(all_new_subgraphs)} second-level subgraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c307ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"üîß Partitioning second level subgraphs...\")\n",
    "\n",
    "if len(network_level_list) > 2:\n",
    "\n",
    "    coarsener = HypergraphCoarsener()\n",
    "\n",
    "    second_level_sparse_assignments = []\n",
    "    subgraphs = all_new_subgraphs\n",
    "\n",
    "    print(subgraphs)\n",
    "\n",
    "    for source_node, subgraph in subgraphs.items():\n",
    "\n",
    "        sub_network = network_level_list[2][source_node]\n",
    "        active_nodes = sub_network.active_nodes\n",
    "        qpu_sizes = {node: sub_network.qpu_graph.nodes[node]['size'] for node in active_nodes}\n",
    "\n",
    "        node_map = {node: idx for idx, node in enumerate(active_nodes)}\n",
    "        \n",
    "        sparse_assignment = set_initial_partitions_sparse(\n",
    "            assignment=parent_assignment,\n",
    "            active_nodes=active_nodes,\n",
    "            qpu_sizes=qpu_sizes,\n",
    "            subgraph=subgraph\n",
    "        )\n",
    "        \n",
    "        # Use coarsen_recursive_subgraph_batch and multilevel optimization\n",
    "        partitioner = FiducciaMattheyses(\n",
    "            circuit=None,\n",
    "            initial_assignment=sparse_assignment,\n",
    "            hypergraph=subgraph,\n",
    "            qpu_info=qpu_sizes,\n",
    "            num_partitions=len(active_nodes),\n",
    "            active_nodes=active_nodes,\n",
    "            limit=num_qubits,\n",
    "            max_gain=4*hypergraph.depth,\n",
    "            passes=10,\n",
    "            stochastic=True,\n",
    "            network=sub_network,\n",
    "            node_map=node_map,\n",
    "            sparse=True\n",
    "        )\n",
    "        results = partitioner.partition(hypergraph_coarsener=HypergraphCoarsener().coarsen_recursive_subgraph_batch, \n",
    "                                        sparse=True, level_limit=100, \n",
    "                                        passes_per_level=10)\n",
    "        \n",
    "        sparse_assignment = results['best_assignment']\n",
    "        final_cost = results['best_cost']\n",
    "\n",
    "\n",
    "\n",
    "        fig = draw_subgraph_mpl(\n",
    "            subgraph,\n",
    "            sparse_assignment,\n",
    "            qpu_sizes,\n",
    "            network=sub_network,\n",
    "            node_map=node_map,\n",
    "            fill_background=True,\n",
    "            show_labels=False\n",
    "        )\n",
    "        \n",
    "        # Check validity of the final sparse assignment\n",
    "        if not check_assignment_validity(sparse_assignment, qpu_sizes, subgraph):\n",
    "            print(\"‚ùå Final sparse assignment is invalid!\")\n",
    "            raise ValueError(\"Final sparse assignment does not respect QPU capacities or active nodes.\")\n",
    "        \n",
    "        second_level_sparse_assignments.append(sparse_assignment)\n",
    "\n",
    "    print(\"\\n‚úÖ Second level subgraph optimization complete!\")\n",
    "    print(\"   Each visualization shows the optimized circuit from each second-level sub-network's perspective\")\n",
    "    print(\"   Real nodes belong to the sub-network, dummy nodes represent external qubits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c6d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from disqco.parti.FM.FM_methods import calculate_full_cost_hetero\n",
    "\n",
    "print(f'Number of second-level sparse assignments: {len(second_level_sparse_assignments)}')\n",
    "print(f'Number of subgraphs: {len(subgraphs)}')\n",
    "parent_assignment = stitch_solution_sparse(subgraphs, second_level_sparse_assignments, num_qubits, depth=hypergraph.depth)\n",
    "\n",
    "final_cost = calculate_full_cost_hetero(hypergraph, parent_assignment, len(initial_network.qpu_sizes), {}, initial_network)\n",
    "\n",
    "print(f\"Final cost of the stitched solution: {final_cost}\")\n",
    "\n",
    "network_level_2 = net_coarsener.network_coarse_list[-3]\n",
    "\n",
    "if check_assignment_validity(parent_assignment, network_level_2.qpu_sizes, hypergraph):\n",
    "    print(\"‚úÖ Final assignment is valid!\")\n",
    "else:\n",
    "    print(\"‚ùå Final assignment is NOT valid! Check capacity constraints and partitioning.\")\n",
    "\n",
    "# draw_graph_tikz(\n",
    "#     hypergraph,\n",
    "#     final_assignment,\n",
    "#     initial_network.qpu_sizes,\n",
    "#     fill_background=True,\n",
    "#     show_labels=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create third level subgraphs\n",
    "print(\"üîß Creating third level subgraphs...\")\n",
    "\n",
    "if len(network_level_list) > 3:\n",
    "\n",
    "    all_new_subgraphs = {}\n",
    "    counter = 0\n",
    "    for i, (source_node, subgraph) in enumerate(subgraphs.items()):\n",
    "        print(f\"\\nüìÇ Processing subgraph {i} (source: {source_node}) for third level...\")\n",
    "        print(f'Counter: {counter}')\n",
    "        counter += 1\n",
    "        \n",
    "        # Get the optimized assignment for this subgraph\n",
    "        optimized_assignment = second_level_sparse_assignments[i]\n",
    "        # Find existing dummy nodes\n",
    "        dummy_nodes = set()\n",
    "        for node in subgraph.nodes:\n",
    "            if isinstance(node, tuple) and len(node) > 0 and node[0] == 'dummy':\n",
    "                dummy_nodes.add(node)\n",
    "        \n",
    "        current_network = network_level_list[2][source_node]\n",
    "        \n",
    "        # Create new subgraphs for second level\n",
    "        new_subgraphs = sub_graph_manager.build_partition_subgraphs(\n",
    "            graph=subgraph,\n",
    "            assignment=optimized_assignment,\n",
    "            current_network=current_network,\n",
    "            new_networks=network_level_list[3],\n",
    "            old_dummy_nodes=dummy_nodes\n",
    "        )\n",
    "\n",
    "        all_new_subgraphs.update(new_subgraphs)\n",
    "\n",
    "    print(f\"‚úÖ Created {len(all_new_subgraphs)} second-level subgraphs\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f20b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third level partitioning\n",
    "\n",
    "if len(network_level_list) > 3:\n",
    "\n",
    "    print(\"üîß Partitioning third level subgraphs...\")\n",
    "\n",
    "    coarsener = HypergraphCoarsener()\n",
    "\n",
    "    # Iterate through dictionary of third level subgraphs\n",
    "    third_level_sparse_assignments = []\n",
    "    subgraphs = all_new_subgraphs\n",
    "\n",
    "    print(subgraphs)\n",
    "\n",
    "    for source_node, subgraph in subgraphs.items():\n",
    "\n",
    "        sub_network = network_level_list[3][source_node]\n",
    "        active_nodes = sub_network.active_nodes\n",
    "        qpu_sizes = {node: sub_network.qpu_graph.nodes[node]['size'] for node in active_nodes}\n",
    "        node_map = {node: idx for idx, node in enumerate(active_nodes)}\n",
    "\n",
    "        dummy_nodes = set()\n",
    "        for node in subgraph.nodes:\n",
    "            if isinstance(node, tuple) and len(node) >= 3 and node[0] == 'dummy':\n",
    "                dummy_nodes.add(node)\n",
    "                qpu = node[2]\n",
    "                node_map[qpu] = len(node_map)  # Assign dummy nodes to the end of the map\n",
    "\n",
    "        \n",
    "        sparse_assignment = set_initial_partitions_sparse(\n",
    "            assignment=parent_assignment,\n",
    "            active_nodes=active_nodes,\n",
    "            qpu_sizes=qpu_sizes,\n",
    "            subgraph=subgraph\n",
    "        )\n",
    "\n",
    "        if not check_assignment_validity(sparse_assignment, qpu_sizes, subgraph):\n",
    "            print(\"‚ùå Sparse assignment is invalid!\")\n",
    "            raise ValueError(\"Sparse assignment does not respect QPU capacities or active nodes.\")\n",
    "        print(f\"Assignment is valid for subgraph {source_node}\")\n",
    "\n",
    "        init_cost = calculate_full_cost_hetero(\n",
    "            hypergraph=subgraph,\n",
    "            assignment=sparse_assignment,\n",
    "            num_partitions=len(active_nodes),\n",
    "            costs={},\n",
    "            network=sub_network,\n",
    "            node_map=node_map,\n",
    "            dummy_nodes=dummy_nodes\n",
    "        )\n",
    "\n",
    "        partitioner = FiducciaMattheyses(\n",
    "            circuit=circuit,\n",
    "            initial_assignment=sparse_assignment,\n",
    "            hypergraph=subgraph,\n",
    "            qpu_info=qpu_sizes,\n",
    "            num_partitions=len(active_nodes),\n",
    "            active_nodes=active_nodes,\n",
    "            limit=num_qubits,\n",
    "            max_gain=4*hypergraph.depth,\n",
    "            passes=10,\n",
    "            stochastic=True,\n",
    "            network=sub_network,\n",
    "            node_map=node_map,\n",
    "            sparse=True\n",
    "        )\n",
    "        results = partitioner.multilevel_partition(coarsener=HypergraphCoarsener().coarsen_recursive_subgraph_batch, \n",
    "                                        sparse=True, level_limit=100, \n",
    "                                        passes_per_level=10)\n",
    "        \n",
    "        sparse_assignment = results['best_assignment']\n",
    "        final_cost = results['best_cost']\n",
    "\n",
    "        # Check validity of the final sparse assignment\n",
    "        if not check_assignment_validity(sparse_assignment, qpu_sizes, subgraph):\n",
    "            print(\"‚ùå Final sparse assignment is invalid!\")\n",
    "            raise ValueError(\"Final sparse assignment does not respect QPU capacities or active nodes.\")\n",
    "        \n",
    "        third_level_sparse_assignments.append(sparse_assignment)\n",
    "\n",
    "    print(\"\\n‚úÖ Third level subgraph optimization complete!\")\n",
    "    print(\"   Each visualization shows the optimized circuit from each third-level sub-network's perspective\")\n",
    "    print(\"   Real nodes belong to the sub-network, dummy nodes represent external qubits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1794d92",
   "metadata": {},
   "source": [
    "## Step 5.8: Stitch Solutions Together\n",
    "\n",
    "The final step is to combine all the optimized subgraph solutions into a single complete assignment using the sparse solution stitching method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitch second-level solutions\n",
    "\n",
    "if len(network_level_list) > 3:\n",
    "\n",
    "    final_assignment_unwrapped = stitch_solution_sparse(\n",
    "        subgraphs, third_level_sparse_assignments, num_qubits, depth=hypergraph.depth\n",
    "    )\n",
    "\n",
    "    network_level_3 = net_coarsener.network_coarse_list[-4]\n",
    "\n",
    "    print(\"Network level 3 QPU sizes:\", network_level_3.qpu_sizes)\n",
    "\n",
    "\n",
    "    # Check final assignment validity\n",
    "    if check_assignment_validity(final_assignment_unwrapped, network_level_3.qpu_sizes, hypergraph):\n",
    "        print(\"‚úÖ Final scond-level assignment is valid!\")\n",
    "    else:\n",
    "        print(\"‚ùå Final -level assignment is NOT valid! Check capacity constraints and partitioning.\")\n",
    "        raise ValueError(\"Final assignment does not satisfy capacity constraints.\")\n",
    "\n",
    "    final_cost = calculate_full_cost_hetero(\n",
    "        hypergraph, final_assignment_unwrapped, len(initial_network.qpu_sizes), {}, initial_network)\n",
    "\n",
    "    print(f\"Final cost of the stitched second-level solution: {final_cost}\")\n",
    "\n",
    "else:\n",
    "    final_assignment_unwrapped = stitch_solution_sparse(\n",
    "        subgraphs, second_level_sparse_assignments, num_qubits, depth=hypergraph.depth\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c060354",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_subgraph_mpl(\n",
    "    hypergraph,\n",
    "    final_assignment_unwrapped,\n",
    "    initial_network.qpu_sizes,\n",
    "    network=initial_network,\n",
    "    show_labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b595449",
   "metadata": {},
   "source": [
    "To run the full process, use the ```run_full_net_coarsened_FM``` function. This can also be accessed via the ```partitioner``` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disqco.parti.FM.net_coarsened_partitioning import run_full_net_coarsened_FM\n",
    "\n",
    "# Example usage:\n",
    "results = run_full_net_coarsened_FM(\n",
    "    hypergraph=hypergraph,\n",
    "    num_qubits=num_qubits,\n",
    "    network=initial_network,\n",
    "    coarsening_factor=4,\n",
    "    passes_per_level=10,\n",
    "    use_multiprocessing=True,\n",
    ")\n",
    "final_assignment = results['best_assignment']\n",
    "print(f\"Final cost: {results['best_cost']}\")\n",
    "\n",
    "\n",
    "\n",
    "# Check final assignment validity\n",
    "if check_assignment_validity(final_assignment, initial_network.qpu_sizes, hypergraph):\n",
    "    print(\"‚úÖ Final assignment is valid!\")\n",
    "else:\n",
    "    print(\"‚ùå Final assignment is NOT valid! Check capacity constraints and partitioning.\")\n",
    "    print(f\"Previous solution validity: {check_assignment_validity(final_assignment_unwrapped, initial_network.qpu_sizes, hypergraph)}\")\n",
    "    raise ValueError(\"Final assignment does not satisfy capacity constraints.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
