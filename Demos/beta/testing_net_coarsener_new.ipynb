{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disqco.circuits.cp_fraction import cp_fraction, cz_fraction\n",
    "from disqco.graphs.GCP_hypergraph import QuantumCircuitHyperGraph\n",
    "from disqco.graphs.hypergraph_methods import calculate_full_cost_hetero\n",
    "from qiskit import transpile\n",
    "from disqco.parti.FM.FM_methods import set_initial_partitions\n",
    "from disqco.circuits.QAOA import QAOA_random\n",
    "from qiskit.circuit.library import QFT, QuantumVolume\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from disqco.graphs.quantum_network import *\n",
    "from disqco.parti.FM.multilevel_FM import MLFM_recursive_hetero\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from disqco.graphs.quantum_network import QuantumNetwork\n",
    "import os\n",
    "import json\n",
    "\n",
    "num_qubits_list = [512]\n",
    "network_types = ['linear']\n",
    "num_partitions_and_coarsening_factors = [(32, 4), (64,4)]\n",
    "\n",
    "###############################################################################\n",
    "# Set up JSON file for storing *all* iteration results (detailed data)\n",
    "###############################################################################\n",
    "detailed_filename = \"benchmark_results_COARENING_POST_PROCESSED_limit8_add.json\"\n",
    "\n",
    "if os.path.exists(detailed_filename):\n",
    "    with open(detailed_filename, \"r\") as f:\n",
    "        detailed_results = json.load(f)\n",
    "else:\n",
    "    detailed_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77e68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_qubits: 512, network_type: linear, num_partitions: 64, coarsening_factor: 4\n",
      "Number of layers: 514\n",
      "Number of layers: 514\n",
      "Initial cost with no grouping:  1246421\n",
      "Initial Cost:  797866\n",
      "Time to coarsen graph: 7.30 seconds\n",
      "Time for multilevel FM: 384.51 seconds\n",
      "Time to coarsen graph: 6.12 seconds\n",
      "Time to coarsen graph: 8.19 seconds\n",
      "Time to coarsen graph: 7.59 seconds\n",
      "Time to coarsen graph: 6.13 seconds\n",
      "Time for multilevel FM: 56.96 seconds\n",
      "Time for multilevel FM: 52.82 seconds\n",
      "Time for multilevel FM: 51.31 seconds\n",
      "Time for multilevel FM: 55.35 seconds\n",
      "Time to coarsen graph: 4.37 seconds\n",
      "Time to coarsen graph: 3.57 seconds\n",
      "Time to coarsen graph: 5.22 seconds\n",
      "Time for multilevel FM: 13.44 seconds\n",
      "Time to coarsen graph: 4.06 seconds\n",
      "Error processing node (510, 432) with sub_node (36, 432): index 36 is out of bounds for axis 0 with size 36\n",
      "Time for multilevel FM: 14.18 seconds\n",
      "Time for multilevel FM: 11.27 seconds\n",
      "Time to coarsen graph: 5.53 seconds\n",
      "Time to coarsen graph: 5.94 seconds\n",
      "Time to coarsen graph: 6.43 seconds\n",
      "Time for multilevel FM: 16.59 seconds\n",
      "Time to coarsen graph: 6.93 seconds\n",
      "Time for multilevel FM: 18.38 seconds\n",
      "Time to coarsen graph: 4.47 seconds\n",
      "Time for multilevel FM: 19.30 seconds\n",
      "Time for multilevel FM: 14.98 seconds\n",
      "Time for multilevel FM: 11.79 seconds\n",
      "Time to coarsen graph: 3.87 seconds\n",
      "Time to coarsen graph: 5.16 seconds\n",
      "Time to coarsen graph: 5.63 seconds\n",
      "Time for multilevel FM: 17.13 seconds\n",
      "Time to coarsen graph: 5.57 seconds\n",
      "Time for multilevel FM: 16.92 seconds\n",
      "Time to coarsen graph: 4.92 seconds\n",
      "Time for multilevel FM: 16.79 seconds\n",
      "Time to coarsen graph: 3.63 seconds\n",
      "Time for multilevel FM: 12.53 seconds\n",
      "Time for multilevel FM: 8.82 seconds\n",
      "Time to coarsen graph: 3.13 seconds\n",
      "Time for multilevel FM: 9.70 seconds\n",
      "Time for multilevel FM: 8.40 seconds\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 36 is out of bounds for axis 0 with size 36",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ~~~~^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"/Users/ftb123/MLQCP_FM/src/disqco/parti/FM/partition_and_build.py\", line 40, in partition_and_build_subgraphs\n    assignment_list_coarse, cost_list_coarse, _ = MLFM_recursive_hetero_mapped(\n                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        graph = subgraph,\n        ^^^^^^^^^^^^^^^^^\n    ...<12 lines>...\n        node_list=node_list,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/ftb123/MLQCP_FM/src/disqco/parti/FM/multilevel_FM.py\", line 465, in MLFM_recursive_hetero_mapped\n    assignment_list, cost_list, time_list = multilevel_FM_hetero(graph_list,\n                                            ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n                                            mapping_list,\n                                            ^^^^^^^^^^^^^\n    ...<12 lines>...\n                                            assignment_map = assignment_map,\n                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n                                            dummy_nodes = dummy_nodes)\n                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/ftb123/MLQCP_FM/src/disqco/parti/FM/multilevel_FM.py\", line 200, in multilevel_FM_hetero\n    best_cost_pass, best_assignment, _ = run_FM_hetero_dummy(\n                                         ~~~~~~~~~~~~~~~~~~~^\n        hypergraph=graph,            # This stage's coarsened hypergraph\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<14 lines>...\n        dummy_nodes=dummy_nodes\n        ^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/ftb123/MLQCP_FM/src/disqco/parti/FM/FM_hetero.py\", line 326, in run_FM_hetero_dummy\n    assignment_list, gain_list = FM_pass_hetero_dummy(\n                                 ~~~~~~~~~~~~~~~~~~~~^\n        hypergraph, max_gain, initial_assignment,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        num_partitions, qpu_info, costs, limit, active_nodes = active_nodes, network = network, node_map = node_map, assignment_map=assignment_map, dummy_nodes=dummy_nodes\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/ftb123/MLQCP_FM/src/disqco/parti/FM/FM_hetero.py\", line 223, in FM_pass_hetero_dummy\n    array = find_all_gains_hetero(hypergraph,active_nodes,assignment,num_partitions, costs, network=network, node_map=node_map, assignment_map=assignment_map, dummy_nodes=dummy_nodes)\n  File \"/Users/ftb123/MLQCP_FM/src/disqco/parti/FM/FM_methods.py\", line 275, in find_all_gains_hetero\n    source = assignment[sub_node[1]][sub_node[0]]\n             ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\nIndexError: index 36 is out of bounds for axis 0 with size 36\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 80\u001b[0m\n\u001b[1;32m     76\u001b[0m     detailed_results\u001b[38;5;241m.\u001b[39mappend(results_entry)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     results_entry \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_qubits\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_qubits,\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetwork_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: network_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed\n\u001b[1;32m     94\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[4], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 58\u001b[0m     cost, final_assignment \u001b[38;5;241m=\u001b[39m \u001b[43mrun_net_coarsened_FM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoarsening_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses_per_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     final_cost \u001b[38;5;241m=\u001b[39m calculate_full_cost_hetero(hypergraph\u001b[38;5;241m=\u001b[39mgraph, assignment\u001b[38;5;241m=\u001b[39mfinal_assignment, num_partitions\u001b[38;5;241m=\u001b[39mnum_partitions, costs \u001b[38;5;241m=\u001b[39m {}, network\u001b[38;5;241m=\u001b[39mnetwork)\n\u001b[1;32m     60\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/MLQCP_FM/src/disqco/parti/FM/net_coarsened_FM.py:178\u001b[0m, in \u001b[0;36mrun_net_coarsened_FM\u001b[0;34m(graph, initial_network, l, multiprocessing, level_limit, passes_per_level)\u001b[0m\n\u001b[1;32m    151\u001b[0m arg_list \u001b[38;5;241m=\u001b[39m [(subgraphs[i],\n\u001b[1;32m    152\u001b[0m             sub_partitions_list[i],\n\u001b[1;32m    153\u001b[0m             qpu_size_list[i],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m             level_limit) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(networks))\n\u001b[1;32m    175\u001b[0m             ]\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multiprocessing:\n\u001b[0;32m--> 178\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition_and_build_subgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mIndexError\u001b[0m: index 36 is out of bounds for axis 0 with size 36"
     ]
    }
   ],
   "source": [
    "from disqco.parti.FM.net_coarsened_FM import run_net_coarsened_FM\n",
    "from disqco.graphs.quantum_network import linear_coupling, grid_coupling\n",
    "import time\n",
    "iterations = 20\n",
    "\n",
    "for num_qubits in num_qubits_list:\n",
    "    for network_type in network_types:\n",
    "        for num_partitions_and_coarsening_factor in num_partitions_and_coarsening_factors:\n",
    "            level_limit = 8  # Set the level limit for coarsening\n",
    "            for iteration in range(iterations):\n",
    "                num_partitions, coarsening_factor = num_partitions_and_coarsening_factor\n",
    "                print(f\"num_qubits: {num_qubits}, network_type: {network_type}, num_partitions: {num_partitions}, coarsening_factor: {coarsening_factor}\")\n",
    "                # Check first whether the json file already contains results for this configuration\n",
    "                existing_results = [entry for entry in detailed_results if entry['num_qubits'] == num_qubits and \n",
    "                                    entry['network_type'] == network_type and\n",
    "                                    entry['num_partitions'] == num_partitions and\n",
    "                                    entry['coarsening_factor'] == coarsening_factor]\n",
    "                if existing_results:\n",
    "                    if existing_results[0]['final_cost'] is not None:\n",
    "                        print(f\"Results already exist for num_qubits: {num_qubits}, network_type: {network_type}, num_partitions: {num_partitions}, coarsening_factor: {coarsening_factor}. Skipping this configuration.\")\n",
    "                        continue\n",
    "                \n",
    "                seed = np.random.randint(0, 10000)\n",
    "                \n",
    "                circuit = cp_fraction(num_qubits=num_qubits,\n",
    "                                        depth=num_qubits,\n",
    "                                        fraction=0.5,\n",
    "                                        seed=seed)\n",
    "                \n",
    "                circuit = transpile(circuit, basis_gates=['cp', 'u'])\n",
    "\n",
    "                qpu_sizes = [int(np.ceil(num_qubits / num_partitions)) + 1 for i in range(num_partitions)]\n",
    "\n",
    "                if network_type == 'linear':\n",
    "                    coupling = linear_coupling(num_partitions)\n",
    "                elif network_type == 'grid':\n",
    "                    coupling = grid_coupling(num_partitions)\n",
    "\n",
    "                initial_qpu_sizes = {i: qpu_sizes[i] for i in range(num_partitions)}\n",
    "                initial_network = QuantumNetwork(qpu_sizes, coupling)\n",
    "\n",
    "                network = deepcopy(initial_network)\n",
    "                initial_graph = QuantumCircuitHyperGraph(circuit, group_gates=True, anti_diag=True)\n",
    "                depth = initial_graph.depth\n",
    "                graph_no_grouping = QuantumCircuitHyperGraph(circuit, group_gates=False, anti_diag=True)\n",
    "\n",
    "                graph = deepcopy(initial_graph)\n",
    "                assignment = set_initial_partitions(network, num_qubits, depth)\n",
    "\n",
    "                initial_cost_no_grouping = calculate_full_cost_hetero(hypergraph=graph_no_grouping, assignment=assignment, num_partitions=num_partitions, costs = {}, network=network)\n",
    "\n",
    "                print(\"Initial cost with no grouping: \", initial_cost_no_grouping)\n",
    "\n",
    "                initial_cost = calculate_full_cost_hetero(hypergraph=graph, assignment=assignment, num_partitions=num_partitions, costs = {}, network=network)\n",
    "\n",
    "                print(\"Initial Cost: \", initial_cost)\n",
    "\n",
    "                try:\n",
    "                    start_time = time.time()\n",
    "                    cost, final_assignment = run_net_coarsened_FM(graph, network, l=coarsening_factor, multiprocessing=True, level_limit=level_limit, passes_per_level=10)\n",
    "                    final_cost = calculate_full_cost_hetero(hypergraph=graph, assignment=final_assignment, num_partitions=num_partitions, costs = {}, network=network)\n",
    "                    end_time = time.time()\n",
    "                    print(\"Final Cost: \", final_cost)\n",
    "                    print(\"Time taken: \", end_time - start_time)\n",
    "                    results_entry = {\n",
    "                        \"num_qubits\": num_qubits,\n",
    "                        \"network_type\": network_type,\n",
    "                        \"num_partitions\": num_partitions,\n",
    "                        \"coarsening_factor\": coarsening_factor,\n",
    "                        \"level_limit\": level_limit,\n",
    "                        \"initial_cost_no_grouping\": initial_cost_no_grouping,\n",
    "                        \"initial_cost\": initial_cost,\n",
    "                        \"final_cost\": final_cost,\n",
    "                        \"iteration\": iteration,\n",
    "                        \"time_taken\": end_time - start_time,\n",
    "                        \"seed\": seed\n",
    "                    }\n",
    "                    detailed_results.append(results_entry)\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "                    print(f\"Error occurred: {e}\")\n",
    "                    results_entry = {\n",
    "                        \"num_qubits\": num_qubits,\n",
    "                        \"network_type\": network_type,\n",
    "                        \"num_partitions\": num_partitions,\n",
    "                        \"coarsening_factor\": coarsening_factor,\n",
    "                        \"level_limit\": level_limit,\n",
    "                        \"initial_cost_no_grouping\": initial_cost_no_grouping,\n",
    "                        \"initial_cost\": initial_cost,\n",
    "                        \"final_cost\": None,\n",
    "                        \"iteration\": iteration,\n",
    "                        \"time_taken\": None,\n",
    "                        \"seed\": seed\n",
    "                    }\n",
    "                    detailed_results.append(results_entry)\n",
    "                    if level_limit > 1:\n",
    "                        level_limit -= 1\n",
    "                        \n",
    "                        \n",
    "                    \n",
    "\n",
    "                with open(detailed_filename, \"w\") as f:\n",
    "                    json.dump(detailed_results, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae5c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:50: SyntaxWarning: \"is not\" with 'int' literal. Did you mean \"!=\"?\n",
      "<>:50: SyntaxWarning: \"is not\" with 'int' literal. Did you mean \"!=\"?\n",
      "/var/folders/s5/7cd6cqh90fd7qlk1kl1bnr0w0000gp/T/ipykernel_38111/3993395770.py:50: SyntaxWarning: \"is not\" with 'int' literal. Did you mean \"!=\"?\n",
      "  if num_qubits is not 512 and network_type != 'grid' and num_partitions != 4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already completed configuration: num_qubits=128, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=128, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=8\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=32\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=16\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=256, network_type=grid, num_partitions=64\n",
      "Skipping already completed configuration: num_qubits=512, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=512, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=512, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=512, network_type=linear, num_partitions=4\n",
      "Skipping already completed configuration: num_qubits=512, network_type=linear, num_partitions=4\n",
      "Direct partitioning for num_qubits: 512, network_type: grid, num_partitions: 4, level_limit: 8\n",
      "Number of layers: 514\n",
      "Time to coarsen graph: 14.88 seconds\n",
      "Initial cost: 45867\n",
      "All passes complete.\n",
      "Final cost: 42428\n",
      "Best cost at level 0: 42428\n",
      "Initial cost: 42428\n",
      "All passes complete.\n",
      "Final cost: 40998\n",
      "Best cost at level 1: 40998\n",
      "Initial cost: 40998\n",
      "All passes complete.\n",
      "Final cost: 39264\n",
      "Best cost at level 2: 39264\n",
      "Initial cost: 39264\n",
      "All passes complete.\n",
      "Final cost: 37298\n",
      "Best cost at level 3: 37298\n",
      "Initial cost: 37298\n",
      "All passes complete.\n",
      "Final cost: 35447\n",
      "Best cost at level 4: 35447\n",
      "Initial cost: 35447\n",
      "All passes complete.\n",
      "Final cost: 33628\n",
      "Best cost at level 5: 33628\n",
      "Initial cost: 33628\n",
      "All passes complete.\n",
      "Final cost: 32172\n",
      "Best cost at level 6: 32172\n",
      "Initial cost: 32172\n",
      "All passes complete.\n",
      "Final cost: 31173\n",
      "Best cost at level 7: 31173\n",
      "Direct partitioning for num_qubits: 512, network_type: grid, num_partitions: 8, level_limit: 8\n",
      "Number of layers: 514\n",
      "Time to coarsen graph: 9.70 seconds\n",
      "Initial cost: 79881\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 104\u001b[0m\n\u001b[1;32m    102\u001b[0m assignment \u001b[38;5;241m=\u001b[39m set_initial_partitions(network, num_qubits, depth)\n\u001b[1;32m    103\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 104\u001b[0m final_assignment_list, final_cost_list, _ \u001b[38;5;241m=\u001b[39m \u001b[43mMLFM_recursive_hetero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43massignment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mqpu_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_qubits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mstochastic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mcosts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mlevel_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    115\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/MLQCP_FM/src/disqco/parti/FM/multilevel_FM.py:404\u001b[0m, in \u001b[0;36mMLFM_recursive_hetero\u001b[0;34m(graph, initial_assignment, qpu_info, limit, pass_list, stochastic, lock_nodes, log, add_initial, costs, level_limit, network, node_map, assignment_map)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     level_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(graph_list)\n\u001b[0;32m--> 404\u001b[0m assignment_list, cost_list, time_list \u001b[38;5;241m=\u001b[39m \u001b[43mmultilevel_FM_hetero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmapping_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43minitial_assignment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_assignment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mqpu_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqpu_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mpass_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpass_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mstochastic\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstochastic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlock_nodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlock_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43madd_initial\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_initial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcosts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcosts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlevel_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevel_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mnode_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43massignment_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43massignment_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assignment_list, cost_list, time_list\n",
      "File \u001b[0;32m~/MLQCP_FM/src/disqco/parti/FM/multilevel_FM.py:200\u001b[0m, in \u001b[0;36mmultilevel_FM_hetero\u001b[0;34m(coarsened_hypergraphs, initial_mapping_list, initial_assignment, qpu_info, limit, pass_list, stochastic, lock_nodes, log, add_initial, costs, level_limit, network, node_map, assignment_map, dummy_nodes)\u001b[0m\n\u001b[1;32m    198\u001b[0m passes \u001b[38;5;241m=\u001b[39m pass_list[i]\n\u001b[1;32m    199\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 200\u001b[0m best_cost_pass, best_assignment, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_FM_hetero_dummy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhypergraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# This stage's coarsened hypergraph\u001b[39;49;00m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_assignment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_assignment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqpu_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqpu_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_partitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_partitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_gain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstochastic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstochastic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactive_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactive_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_initial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_initial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcosts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcosts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43massignment_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massignment_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdummy_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_nodes\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()       \n\u001b[1;32m    219\u001b[0m level_time \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/MLQCP_FM/src/disqco/parti/FM/FM_hetero.py:326\u001b[0m, in \u001b[0;36mrun_FM_hetero_dummy\u001b[0;34m(hypergraph, initial_assignment, qpu_info, num_partitions, limit, max_gain, passes, stochastic, active_nodes, log, add_initial, costs, network, node_map, assignment_map, dummy_nodes)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# print(\"Starting FM passes...\")\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# print(\"Assignment node (16, 23):\", initial_assignment[23][16])\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(passes):\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;66;03m# print(f\"Pass number: {n}\")\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     assignment_list, gain_list \u001b[38;5;241m=\u001b[39m \u001b[43mFM_pass_hetero_dummy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhypergraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_gain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_assignment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_partitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqpu_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_nodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mactive_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massignment_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massignment_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_nodes\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# Decide how to pick new assignment depending on stochastic or not\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stochastic:\n",
      "File \u001b[0;32m~/MLQCP_FM/src/disqco/parti/FM/FM_hetero.py:247\u001b[0m, in \u001b[0;36mFM_pass_hetero_dummy\u001b[0;34m(hypergraph, max_gain, assignment, num_partitions, qpu_info, costs, limit, active_nodes, network, node_map, assignment_map, dummy_nodes)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     source \u001b[38;5;241m=\u001b[39m assignment[node[\u001b[38;5;241m1\u001b[39m]][node[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 247\u001b[0m assignment_new, array, buckets \u001b[38;5;241m=\u001b[39m \u001b[43mtake_action_and_update_hetero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypergraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mbuckets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mnum_partitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mlock_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43massignment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mcosts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mnode_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43massignment_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massignment_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# assignment_new, array, buckets = take_action_and_update_dict_simple(hypergraph,node,destination,array,buckets,num_partitions,lock_dict,assignment,costs)\u001b[39;00m\n\u001b[1;32m    262\u001b[0m update_spaces(node,source,destination,spaces)\n",
      "File \u001b[0;32m~/MLQCP_FM/src/disqco/parti/FM/FM_methods.py:807\u001b[0m, in \u001b[0;36mtake_action_and_update_hetero\u001b[0;34m(hypergraph, node, destination, array, buckets, num_partitions, lock_dict, assignment, costs, network, node_map, assignment_map)\u001b[0m\n\u001b[1;32m    804\u001b[0m next_action \u001b[38;5;241m=\u001b[39m (next_rec_node[\u001b[38;5;241m1\u001b[39m], next_rec_node[\u001b[38;5;241m0\u001b[39m], next_destination)\n\u001b[1;32m    806\u001b[0m next_rec_counts_b, source1 \u001b[38;5;241m=\u001b[39m update_counts(rec_counts_pre, next_rec_node, next_destination, assignment, assignment_map\u001b[38;5;241m=\u001b[39massignment_map)\n\u001b[0;32m--> 807\u001b[0m next_rec_config_b \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_rec_counts_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_destination\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m next_rec_counts_ab, source2 \u001b[38;5;241m=\u001b[39m update_counts(rec_counts_a, next_rec_node, next_destination, assignment_new, assignment_map\u001b[38;5;241m=\u001b[39massignment_map)\n\u001b[1;32m    810\u001b[0m next_rec_config_ab \u001b[38;5;241m=\u001b[39m update_config(rec_config_a, next_rec_counts_ab, source2, next_destination)\n",
      "File \u001b[0;32m~/MLQCP_FM/src/disqco/parti/FM/FM_methods.py:351\u001b[0m, in \u001b[0;36mupdate_config\u001b[0;34m(old_config, new_counts, source, destination)\u001b[0m\n\u001b[1;32m    347\u001b[0m             new_config[destination] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_config\n\u001b[0;32m--> 351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate_config\u001b[39m(old_config, \n\u001b[1;32m    352\u001b[0m                   new_counts, \n\u001b[1;32m    353\u001b[0m                   source, \n\u001b[1;32m    354\u001b[0m                   destination):\n\u001b[1;32m    355\u001b[0m     new_config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mlist\u001b[39m(old_config))\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_counts[source] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now set up same testing loop using standard MLFM-R\n",
    "# Read through JSON file to find random seeds to generate each circuit\n",
    "import time\n",
    "\n",
    "\n",
    "from disqco.parti.FM.multilevel_FM import MLFM_recursive_hetero\n",
    "\n",
    "# final_assignment_list, final_cost_list, _ = MLFM_recursive_hetero(graph,\n",
    "#                                                                     assignment,\n",
    "#                                                                     qpu_sizes,\n",
    "#                                                                     limit=num_qubits,\n",
    "#                                                                     network=network,\n",
    "#                                                                     log=True,\n",
    "#                                                                     stochastic=True,\n",
    "#                                                                     costs=costs, \n",
    "#                                                                     level_limit=None)\n",
    "\n",
    "\n",
    "with open(detailed_filename, \"r\") as f:\n",
    "    detailed_results = json.load(f)\n",
    "\n",
    "\n",
    "direct_partitioning_filename = \"benchmark_results_COARSENING_POST_PROCESSED_direct_partitioning.json\"\n",
    "if os.path.exists(direct_partitioning_filename):\n",
    "    with open(direct_partitioning_filename, \"r\") as f:\n",
    "        direct_results = json.load(f)\n",
    "else:\n",
    "    direct_results = []\n",
    "\n",
    "completed_set = set()\n",
    "\n",
    "for result in direct_results:\n",
    "    num_qubits = result['num_qubits']\n",
    "    network_type = result['network_type']\n",
    "    num_partitions = result['num_partitions']\n",
    "    completed_set.add((num_qubits, network_type, num_partitions))\n",
    "\n",
    "for result in detailed_results:\n",
    "\n",
    "    num_qubits = result['num_qubits']\n",
    "    network_type = result['network_type']\n",
    "    num_partitions = result['num_partitions']\n",
    "    level_limit = result['level_limit']\n",
    "    initial_cost_no_grouping = result['initial_cost_no_grouping']\n",
    "    initial_cost = result['initial_cost']\n",
    "    final_cost = result['final_cost']\n",
    "    iteration = result['iteration']\n",
    "    time_taken = result['time_taken']\n",
    "    seed = result['seed']\n",
    "    if num_qubits is not 512 and network_type != 'grid' and num_partitions != 4:\n",
    "        continue\n",
    "    if (num_qubits, network_type, num_partitions) in completed_set:\n",
    "        print(f\"Skipping already completed configuration: num_qubits={num_qubits}, network_type={network_type}, num_partitions={num_partitions}\")\n",
    "        continue\n",
    "    completed_set.add((num_qubits, network_type, num_partitions))\n",
    "    \n",
    "    if num_partitions <= 16:\n",
    "        level_limit = 8\n",
    "    else:\n",
    "        results_entry = {\n",
    "            \"num_qubits\": num_qubits,\n",
    "            \"network_type\": network_type,\n",
    "            \"num_partitions\": num_partitions,\n",
    "            \"level_limit\": 1,\n",
    "            \"initial_cost_no_grouping\": initial_cost_no_grouping,\n",
    "            \"initial_cost\": initial_cost,\n",
    "            \"final_cost\": initial_cost,  # No final cost for direct partitioning as too large\n",
    "            \"iteration\": iteration,\n",
    "            \"time_taken\": None,\n",
    "            \"seed\": seed\n",
    "        }\n",
    "\n",
    "        direct_results.append(results_entry)\n",
    "        with open(direct_partitioning_filename, \"w\") as f:\n",
    "            json.dump(direct_results, f, indent=2)\n",
    "        print(f\"Skipping direct partitioning for num_qubits: {num_qubits}, network_type: {network_type}, num_partitions: {num_partitions} as level_limit is 1\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Direct partitioning for num_qubits: {num_qubits}, network_type: {network_type}, num_partitions: {num_partitions}, level_limit: {level_limit}\")\n",
    "    circuit = cp_fraction(num_qubits=num_qubits,\n",
    "                            depth=num_qubits,\n",
    "                            fraction=0.5,\n",
    "                            seed=seed)\n",
    "    \n",
    "    circuit = transpile(circuit, basis_gates=['cp', 'u'])\n",
    "\n",
    "    qpu_sizes = [int(np.ceil(num_qubits / num_partitions)) + 1 for i in range(num_partitions)]\n",
    "\n",
    "    if network_type == 'linear':\n",
    "        coupling = linear_coupling(num_partitions)\n",
    "    elif network_type == 'grid':\n",
    "        coupling = grid_coupling(num_partitions)\n",
    "\n",
    "    initial_qpu_sizes = {i: qpu_sizes[i] for i in range(num_partitions)}\n",
    "    network = QuantumNetwork(qpu_sizes, coupling)\n",
    "\n",
    "\n",
    "    graph = QuantumCircuitHyperGraph(circuit, group_gates=True, anti_diag=True)\n",
    "\n",
    "    depth = graph.depth\n",
    "\n",
    "    assignment = set_initial_partitions(network, num_qubits, depth)\n",
    "    start_time = time.time()\n",
    "    final_assignment_list, final_cost_list, _ = MLFM_recursive_hetero(graph,\n",
    "                                                                    assignment,\n",
    "                                                                    qpu_sizes,\n",
    "                                                                    limit=num_qubits,\n",
    "                                                                    network=network,\n",
    "                                                                    log=True,\n",
    "                                                                    stochastic=True,\n",
    "                                                                    costs={},\n",
    "                                                                    level_limit=level_limit)\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_taken = end_time - start_time\n",
    "    \n",
    "    results_entry = {\n",
    "        \"num_qubits\": num_qubits,\n",
    "        \"network_type\": network_type,\n",
    "        \"num_partitions\": num_partitions,\n",
    "        \"level_limit\": level_limit,\n",
    "        \"initial_cost_no_grouping\": initial_cost_no_grouping,\n",
    "        \"initial_cost\": initial_cost,\n",
    "        \"final_cost\": min(final_cost_list),\n",
    "        \"iteration\": iteration,\n",
    "        \"time_taken\": time_taken,\n",
    "        \"seed\": seed}\n",
    "    \n",
    "    direct_results.append(results_entry)\n",
    "\n",
    "    with open(direct_partitioning_filename, \"w\") as f:\n",
    "        json.dump(direct_results, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
